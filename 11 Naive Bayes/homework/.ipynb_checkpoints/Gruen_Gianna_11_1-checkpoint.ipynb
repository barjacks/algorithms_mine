{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): scipy in /Users/gcg/.virtualenvs/ddj/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.6.2 in /Users/gcg/.virtualenvs/ddj/lib/python3.5/site-packages (from scipy)\n",
      "Requirement already satisfied (use --upgrade to upgrade): sklearn in /Users/gcg/.virtualenvs/ddj/lib/python3.5/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-learn in /Users/gcg/.virtualenvs/ddj/lib/python3.5/site-packages (from sklearn)\n",
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/gcg/.virtualenvs/ddj/lib/python3.5/site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install sklearn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tar -zxf 20_newsgroups.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20_newsgroups/alt.atheism/0000000',\n",
       " '20_newsgroups/alt.atheism/0000001',\n",
       " '20_newsgroups/alt.atheism/0000002',\n",
       " '20_newsgroups/alt.atheism/0000003',\n",
       " '20_newsgroups/alt.atheism/0000004',\n",
       " '20_newsgroups/alt.atheism/0000005',\n",
       " '20_newsgroups/alt.atheism/0000006',\n",
       " '20_newsgroups/alt.atheism/0000007',\n",
       " '20_newsgroups/alt.atheism/0000008',\n",
       " '20_newsgroups/alt.atheism/0000009',\n",
       " '20_newsgroups/alt.atheism/0000010',\n",
       " '20_newsgroups/alt.atheism/0000011',\n",
       " '20_newsgroups/alt.atheism/0000012',\n",
       " '20_newsgroups/alt.atheism/0000013',\n",
       " '20_newsgroups/alt.atheism/0000014',\n",
       " '20_newsgroups/alt.atheism/0000015',\n",
       " '20_newsgroups/alt.atheism/0000016',\n",
       " '20_newsgroups/alt.atheism/0000017',\n",
       " '20_newsgroups/alt.atheism/0000018',\n",
       " '20_newsgroups/alt.atheism/0000019']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob finds files matching a certain filename pattern\n",
    "import glob\n",
    "\n",
    "# Give me all the text files\n",
    "paths = glob.glob('20_newsgroups/*/*')\n",
    "paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>group</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Archive-name: atheism/resources\\nAlt-atheism-a...</td>\n",
       "      <td>0000000</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>20_newsgroups/alt.atheism/0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archive-name: atheism/introduction\\nAlt-atheis...</td>\n",
       "      <td>0000001</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>20_newsgroups/alt.atheism/0000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In article &lt;65974@mimsy.umd.edu&gt;\\nmangoe@cs.um...</td>\n",
       "      <td>0000002</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>20_newsgroups/alt.atheism/0000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dmn@kepler.unh.edu (...until kings become phil...</td>\n",
       "      <td>0000003</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>20_newsgroups/alt.atheism/0000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In article &lt;N4HY.93Apr5120934@harder.ccr-p.ida...</td>\n",
       "      <td>0000004</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>20_newsgroups/alt.atheism/0000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content filename        group  \\\n",
       "0  Archive-name: atheism/resources\\nAlt-atheism-a...  0000000  alt.atheism   \n",
       "1  Archive-name: atheism/introduction\\nAlt-atheis...  0000001  alt.atheism   \n",
       "2  In article <65974@mimsy.umd.edu>\\nmangoe@cs.um...  0000002  alt.atheism   \n",
       "3  dmn@kepler.unh.edu (...until kings become phil...  0000003  alt.atheism   \n",
       "4  In article <N4HY.93Apr5120934@harder.ccr-p.ida...  0000004  alt.atheism   \n",
       "\n",
       "                            pathname  \n",
       "0  20_newsgroups/alt.atheism/0000000  \n",
       "1  20_newsgroups/alt.atheism/0000001  \n",
       "2  20_newsgroups/alt.atheism/0000002  \n",
       "3  20_newsgroups/alt.atheism/0000003  \n",
       "4  20_newsgroups/alt.atheism/0000004  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = []\n",
    "for folder in paths:\n",
    "    with open(folder, encoding = \"latin-1\") as ng_file:\n",
    "        ng = {\n",
    "            'pathname': folder,\n",
    "            'filename': folder.split('/')[-1],\n",
    "            'group': folder.split('/')[-2],\n",
    "            'content': ng_file.read()\n",
    "        }\n",
    "    newsgroups.append(ng)\n",
    "newsgroups_df = pd.DataFrame(newsgroups)\n",
    "newsgroups_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use the LabelEncoder to convert the group names to numeric labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(newsgroups_df['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 19, 19, 19])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(newsgroups_df['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>group</th>\n",
       "      <th>pathname</th>\n",
       "      <th>newsgroups_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20414</th>\n",
       "      <td>In article &lt;1rc1f3INN7rl@emx.cc.utexas.edu&gt; \\n...</td>\n",
       "      <td>0019994</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>20_newsgroups/talk.religion.misc/0019994</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20415</th>\n",
       "      <td>In article &lt;1993Apr26.231845.13843@digi.lonest...</td>\n",
       "      <td>0019995</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>20_newsgroups/talk.religion.misc/0019995</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20416</th>\n",
       "      <td>In article &lt;C64H4w.BFH@darkside.osrhe.uoknor.e...</td>\n",
       "      <td>0019996</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>20_newsgroups/talk.religion.misc/0019996</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content filename  \\\n",
       "20414  In article <1rc1f3INN7rl@emx.cc.utexas.edu> \\n...  0019994   \n",
       "20415  In article <1993Apr26.231845.13843@digi.lonest...  0019995   \n",
       "20416  In article <C64H4w.BFH@darkside.osrhe.uoknor.e...  0019996   \n",
       "\n",
       "                    group                                  pathname  \\\n",
       "20414  talk.religion.misc  20_newsgroups/talk.religion.misc/0019994   \n",
       "20415  talk.religion.misc  20_newsgroups/talk.religion.misc/0019995   \n",
       "20416  talk.religion.misc  20_newsgroups/talk.religion.misc/0019996   \n",
       "\n",
       "       newsgroups_label  \n",
       "20414                19  \n",
       "20415                19  \n",
       "20416                19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_df['newsgroups_label'] = le.transform(newsgroups_df['group'])\n",
    "newsgroups_df.head(3)\n",
    "newsgroups_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pick out 10 words or phrases to use as manually created features. Doing an 80/20 train/test split, how well does a Naive Bayes classifier do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "atheism\n",
    "graphics\n",
    "motorcycles\n",
    "baseball\n",
    "hockey\n",
    "crypt\n",
    "med\n",
    "space\n",
    "guns\n",
    "mideast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups_df['has_atheism'] = newsgroups_df['content'].str.contains('atheism')\n",
    "newsgroups_df['has_graphics'] = newsgroups_df['content'].str.contains('graphics')\n",
    "newsgroups_df['has_motorcycles'] = newsgroups_df['content'].str.contains('motocycles')\n",
    "newsgroups_df['has_baseball'] = newsgroups_df['content'].str.contains('baseball')\n",
    "newsgroups_df['has_hockey'] = newsgroups_df['content'].str.contains('hockey')\n",
    "newsgroups_df['has_crypt'] = newsgroups_df['content'].str.contains('crypt')\n",
    "newsgroups_df['has_med'] = newsgroups_df['content'].str.contains('med')\n",
    "newsgroups_df['has_space'] = newsgroups_df['content'].str.contains('space')\n",
    "newsgroups_df['has_guns'] = newsgroups_df['content'].str.contains('guns')\n",
    "newsgroups_df['has_mideast'] = newsgroups_df['content'].str.contains('mideast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'filename', 'group', 'pathname', 'newsgroups_label',\n",
       "       'has_atheism', 'has_graphics', 'has_motorcycles', 'has_baseball',\n",
       "       'has_hockey', 'has_crypt', 'has_med', 'has_space', 'has_guns',\n",
       "       'has_mideast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "nbx_train, nbx_test, nby_train, nby_test = train_test_split(\n",
    "    newsgroups_df[['has_atheism', 'has_graphics', 'has_motorcycles', 'has_baseball',\n",
    "       'has_hockey', 'has_crypt', 'has_med', 'has_space', 'has_guns',\n",
    "       'has_mideast']], # the first is our FEATURES\n",
    "    newsgroups_df['newsgroups_label'], # the second parameter is the LABEL (0-16, southern us, brazilian, anything really)\n",
    "    test_size=0.2) # 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "clf = naive_bayes.BernoulliNB()\n",
    "clf.fit(nbx_train, nby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1730851650033674"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(nbx_train, nby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16307541625857003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(nbx_test, nby_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use a CountVectorizer to automatically create your list of features. Doing an 80/20 train/test split, how well can a Naive Bayes classifier do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "#kernel dies without max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(newsgroups_df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20417x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1542471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_features = vectorizer.transform(newsgroups_df['content'])\n",
    "all_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    all_word_features,\n",
    "    newsgroups_df['content'], \n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = naive_bayes.BernoulliNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1223290271230025"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021302644466209598"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So Naive Bayes did better with the manually selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PUSH THAT SCORE UP! You can adjust ngrams, max_features and any other options of the vectorizer, or try a decision tree or any other type of classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bc I couldn't run the Count Vectorizer without max_features and ngrams don't make sense here, bc it is more about single words(?), I would like to try Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.fit(nbx_train, nby_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.174003551093\n",
      "Testing score: 0.165034280118\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score:\", tree_clf.score(nbx_train, nby_train))\n",
    "\n",
    "print(\"Testing score:\", tree_clf.score(nbx_test, nby_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Same results for Naive Bayes and Random forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write 15 sentences that, when run against the predictor, are put in 15 separate newsgroups (list the names of the newsgroups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I believe atheism is also a religion\",\n",
    "    \"I love graphics\",\n",
    "    \"We rode a motorcycle on the weekend\",\n",
    "    \"I never played or watched baseball\",\n",
    "    \"Who likes hockey, really?!\"\n",
    "    \"You would want to encrypt your emails\",\n",
    "    \"I really love the pharma industry for all the medicine provided\",\n",
    "    \"How does medical care in space work out?\",\n",
    "    \"Do you have a collection of guns?\",\n",
    "    \"What's your favourite country in the mideast?\",\n",
    "    \"The US should pass a anti-gun law to control weapon sales\",\n",
    "    \"You should teach how to crypt in schools\",\n",
    "    \"Have you ever fired guns?\",\n",
    "    \"These are really cool graphics. How did you make them?\",\n",
    "    \"Mideast politics are really complicated.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences_words_features = vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x74 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 98 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_words_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = naive_bayes.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(vectorizer.transform(newsgroups_df['content']), newsgroups_df['newsgroups_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  6,  8,  6, 10,  6,  1,  6,  6, 16,  6,  6,  1,  6])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(sentences_words_features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['misc.forsale', 'misc.forsale', 'rec.motorcycles', 'misc.forsale',\n",
       "       'rec.sport.hockey', 'misc.forsale', 'comp.graphics', 'misc.forsale',\n",
       "       'misc.forsale', 'talk.politics.guns', 'misc.forsale',\n",
       "       'misc.forsale', 'comp.graphics', 'misc.forsale'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is predicting badly, but it is also with the training data, so it is consistent in a way. \n",
    "# I'd assume that this is a case for improving training data, to aslo improve the resule \n",
    "# (ie go for word combinations instead of single words.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
